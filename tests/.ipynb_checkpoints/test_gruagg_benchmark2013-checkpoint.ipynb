{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##===================== Statements & Copyright ===================##\n",
    "\"\"\"\n",
    "AUTHOR:  Xiaolong Li, VT\n",
    "CONTENT: Used for Video-text project\n",
    "LOG:     add code for agg model \n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import sys\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "\n",
    "import _init_paths\n",
    "from model import model\n",
    "from model import model_flow_east\n",
    "from pwc.dataset_base import _DEFAULT_DS_VAL_OPTIONS\n",
    "from pwc.model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_VAL_OPTIONS\n",
    "from pwc.net_options import cfg_lg, cfg_sm\n",
    "from config.configrnn import get_config\n",
    "from model.model_aggregation import Aggregation\n",
    "from lstm import model_gru_agg\n",
    "from utils.icdar import restore_rectangle\n",
    "import lanms\n",
    "from utils.eval import resize_image, sort_poly, detect\n",
    "from utils.icdar import load_annotations_solo, check_and_validate_polys\n",
    "from utils.nms_highlevel import intersection\n",
    "import matplotlib.pyplot as plt\n",
    "now = datetime.now()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# used for iou searching and selecting TP, FP, FN #\n",
    "def eval_single_frame(target, box):\n",
    "    \"\"\"\n",
    "    input params:\n",
    "        target, python ordered dict\n",
    "        box, sorted boxes dict from predictions\n",
    "    \"\"\"\n",
    "    TP   = 0\n",
    "    FP   = 0\n",
    "    FN   = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    F_measure = 0\n",
    "    if not len(box['text_lines']) == 0:\n",
    "        for t in target:\n",
    "            d = np.array(t, dtype='int32')\n",
    "            is_best = 0\n",
    "            for m in box['text_lines']:\n",
    "                n = np.array([m['x0'], m['y0'], m['x1'], m['y1'], m['x2'],\n",
    "                              m['y2'], m['x3'], m['y3']], dtype='int32')\n",
    "\n",
    "                # pick out the best match\n",
    "                iou = intersection(n, d)\n",
    "                if iou>is_best:\n",
    "                    is_best = iou\n",
    "            if is_best > 0.5:\n",
    "                TP = TP+1\n",
    "            elif is_best == 0:\n",
    "                FN = FN +1\n",
    "            else:\n",
    "                FP = FP+1\n",
    "        if TP > 0:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall    = TP/(TP+FN)\n",
    "            F_measure = 2*precision*recall/(precision+recall)\n",
    "#     if len(target) == 0:\n",
    "#         precision = 1\n",
    "#         recall    = 1\n",
    "#         F_measure = 1\n",
    "    return precision, recall, F_measure\n",
    "\n",
    "\n",
    "def draw_illu(illu, rst):\n",
    "    for t in rst['text_lines']:\n",
    "        d = np.array([t['x0'], t['y0'], t['x1'], t['y1'], t['x2'],\n",
    "                      t['y2'], t['x3'], t['y3']], dtype='int32')\n",
    "        d = d.reshape(-1, 2)\n",
    "        cv2.polylines(illu, [d], isClosed=True, thickness=2, color=(255, 0, 0))\n",
    "    return illu\n",
    "\n",
    "\n",
    "def draw_illu_gt(illu, rst, p, r, f):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.3\n",
    "    fontColor = (255, 255, 255)\n",
    "    lineType = 1\n",
    "    infos = 'Precision ' + str(p)+ ', recall ' + str(r) + ', F_measure ' + str(f)\n",
    "    cv2.putText(illu, infos,\n",
    "                (2, 20),\n",
    "                font,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                lineType)\n",
    "    for t in rst:\n",
    "        d1 = t.reshape(-1, 2).astype(np.int32)\n",
    "        cv2.polylines(illu, [d1], isClosed=True, thickness=2, color=(0, 0, 0))\n",
    "        # bottomLeftCornerOfText = (int(t['x0']), int(t['y0']))\n",
    "\n",
    "    return illu\n",
    "\n",
    "\n",
    "def box_generation(index, img, frame_height, frame_width, f_score, f_geometry, polys_array_list, tags_array_list, start):\n",
    "    timer = collections.OrderedDict([\n",
    "                        ('net', 0),\n",
    "                        ('restore', 0),\n",
    "                        ('nms', 0)\n",
    "                                   ])\n",
    "    timer['net'] = time.time() - start\n",
    "\n",
    "    boxes, timer = detect(score_map=f_score, geo_map=f_geometry, timer=timer)\n",
    "    ratio_w = 512/frame_width\n",
    "    ratio_h = 512/frame_height\n",
    "    if boxes is not None:\n",
    "        scores = boxes[:,8].reshape(-1)\n",
    "        boxes = boxes[:, :8].reshape((-1, 4, 2))\n",
    "        boxes[:, :, 0] /= ratio_w\n",
    "        boxes[:, :, 1] /= ratio_h\n",
    "\n",
    "    duration = time.time() - start\n",
    "    timer['overall'] = duration\n",
    "    text_lines = []\n",
    "    if boxes is not None:\n",
    "        text_lines = []\n",
    "        for box, score in zip(boxes, scores):\n",
    "            box = sort_poly(box.astype(np.int32))\n",
    "            if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3]-box[0]) < 5:\n",
    "                continue\n",
    "            tl = collections.OrderedDict(zip(\n",
    "                ['x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3'],\n",
    "                map(float, box.flatten())))\n",
    "            tl['score'] = float(score)\n",
    "            text_lines.append(tl)\n",
    "    pred = {\n",
    "        'text_lines': text_lines\n",
    "    }\n",
    "    text_polys, text_tags = polys_array_list[index], tags_array_list[index]\n",
    "    text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (frame_height, frame_width))\n",
    "    # out.write(new_img)\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>Evaluation>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    targets = text_polys\n",
    "    precision, recall, f1 = eval_single_frame(targets, pred)\n",
    "    new_img = draw_illu(img.copy(), pred)\n",
    "    new_img1 = draw_illu_gt(new_img.copy(), targets, precision, recall, f1)\n",
    "    return precision, recall, f1, new_img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Video_39_2_3', 'Video_48_6_4', 'Video_5_3_2', 'Video_17_3_1', 'Video_35_2_3', 'Video_6_3_2', 'Video_11_4_1', 'Video_20_5_1', 'Video_49_6_4', 'Video_23_5_2', 'Video_44_6_4', 'Video_32_2_3', 'Video_53_7_4', 'Video_24_5_2', 'Video_1_1_2']\n"
     ]
    }
   ],
   "source": [
    "video_set = []\n",
    "test_data_path = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/test/'\n",
    "for root, dirs, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4'):\n",
    "            video_set.append(os.path.splitext(file)[0])\n",
    "print(video_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now it knows it's in a remote cluster\n"
     ]
    }
   ],
   "source": [
    "############################# 1. Glabol Variables #########################################\n",
    "################### 1.1 Training Setup\n",
    "ICDAR2013 = '/media/dragonx/DataLight/ICDAR2013/'\n",
    "ARC = '/media/dragonx/DataStorage/ARC/'\n",
    "############ Macros ############\n",
    "BASIC = \"basic\"\n",
    "CUDNN = \"cudnn\"\n",
    "BLOCK = \"block\"\n",
    "CONV  = \"conv2d\"\n",
    "CUDNN_INPUT_LINEAR_MODE = \"linear_input\"\n",
    "CUDNN_RNN_BIDIRECTION   = \"bidirection\"\n",
    "CUDNN_RNN_UNIDIRECTION = \"unidirection\"\n",
    "if platform.uname()[1] != 'dragonx-H97N-WIFI':\n",
    "    print(\"Now it knows it's in a remote cluster\")\n",
    "    ARC = '/work/cascades/lxiaol9/ARC/'\n",
    "    ICDAR2013 = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/'\n",
    "\n",
    "tf.app.flags.DEFINE_string('mode', 'test', 'whether debugging or real running')\n",
    "tf.app.flags.DEFINE_string(\"model\", \"test\", \"A type of model. Possible options are: small, medium, large.\")\n",
    "tf.app.flags.DEFINE_integer('input_size', 512, '')\n",
    "tf.app.flags.DEFINE_integer('batch_size_per_gpu', 8, '')\n",
    "tf.app.flags.DEFINE_integer('seq_len', 5, '')\n",
    "tf.app.flags.DEFINE_integer('num_steps', 5, '')\n",
    "tf.app.flags.DEFINE_string('gpu_list', '0,1', '')\n",
    "tf.app.flags.DEFINE_float('moving_average_decay', 0.9997, '')\n",
    "tf.app.flags.DEFINE_integer('num_gpus', 2, '')\n",
    "\n",
    "tf.app.flags.DEFINE_string('geometry', 'RBOX', 'which geometry to generate, RBOX or QUAD')\n",
    "tf.app.flags.DEFINE_string('checkpoint_path', '/work/cascades/lxiaol9/ARC/EAST/checkpoints/FLOW_east/20181109-210436/model.ckpt-31902', '')\n",
    "# Model 1: EAST\n",
    "tf.app.flags.DEFINE_string('pretrained_model_path', ARC + \"EAST/checkpoints/east/20180921-173054/model.ckpt-56092\", '')\n",
    "# Model 2: PWC-net\n",
    "tf.app.flags.DEFINE_string('flownet_type', \"large\", '')\n",
    "tf.app.flags.DEFINE_string(\"rnn_mode\", CONV, \"one of CUDNN: BASIC, BLOCK\")\n",
    "# Model 3: AGG\n",
    "tf.app.flags.DEFINE_string(\"prev_checkpoint_path\", \"/work/cascades/lxiaol9/ARC/EAST/checkpoints/GRU_agg/20181202-225518/model.ckpt-3521\", 'path' )\n",
    "\n",
    "tf.app.flags.DEFINE_boolean(\"vis\", True, '')\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/test_results_gruagg/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue training from previous checkpoint\n",
      "INFO:tensorflow:Restoring parameters from /work/cascades/lxiaol9/ARC/EAST/checkpoints/GRU_agg/20181202-225518/model.ckpt-3521\n",
      "Building model...\n",
      "WARNING:tensorflow:From /home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:104: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "... model built.\n",
      "Loading model checkpoint /work/cascades/lxiaol9/ARC/PWC/checkpoints/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000 for eval or testing...\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /work/cascades/lxiaol9/ARC/PWC/checkpoints/pwcnet-lg-6-2-multisteps-chairsthingsmix/pwcnet.ckpt-595000\n",
      "... model loaded\n",
      "resnet_v1_50/block1 (?, ?, ?, 256)\n",
      "resnet_v1_50/block2 (?, ?, ?, 512)\n",
      "resnet_v1_50/block3 (?, ?, ?, 1024)\n",
      "resnet_v1_50/block4 (?, ?, ?, 2048)\n",
      "Shape of f_0 (?, ?, ?, 2048)\n",
      "Shape of f_1 (?, ?, ?, 512)\n",
      "Shape of f_2 (?, ?, ?, 256)\n",
      "Shape of f_3 (?, ?, ?, 64)\n",
      "Shape of h_0 (?, ?, ?, 2048), g_0 (?, ?, ?, 2048)\n",
      "Shape of h_1 (?, ?, ?, 128), g_1 (?, ?, ?, 128)\n",
      "Shape of h_2 (?, ?, ?, 64), g_2 (?, ?, ?, 64)\n",
      "Shape of h_3 (?, ?, ?, 32), g_3 (?, ?, ?, 32)\n",
      "INFO:tensorflow:Restoring parameters from /work/cascades/lxiaol9/ARC/EAST/checkpoints/east/20180921-173054/model.ckpt-56092\n",
      "Now testing Video_48_6_4 with 510 frames\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,1) into shape (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e255d3be559e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e255d3be559e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msco_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mf_geometry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_img1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_geometry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolys_array_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_array_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"New Model:results on frame {} is P:{}, R{}, F:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mnew_detections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0c88c7740982>\u001b[0m in \u001b[0;36mbox_generation\u001b[0;34m(index, img, frame_height, frame_width, f_score, f_geometry, polys_array_list, tags_array_list, start)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_geometry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mratio_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mframe_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mratio_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mframe_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/videoText2018/flow-EAST/tests/../utils/eval.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(score_map, geo_map, timer, score_map_thresh, box_thresh, nms_thres)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_box_restored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_box_restored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxy_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxy_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtimer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'restore'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# nms part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0,1) into shape (0)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "FLAGS.vis = True\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>> specs for AGG >>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
    "FLAGS.batch_size_per_gpu = 1\n",
    "FLAGS.seq_len = 5\n",
    "FLAGS.gpu_list ='1'\n",
    "FLAGS.num_gpus  = 1\n",
    "def main(argv=None):\n",
    "    config = get_config(FLAGS)\n",
    "    config.batch_size = FLAGS.batch_size_per_gpu * FLAGS.num_gpus\n",
    "    config.num_layers = 3\n",
    "    config.num_steps  = 5\n",
    "    ######################## Set up model configurations ######################\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> EAST model options >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    checkpoint_path = '/work/cascades/lxiaol9/ARC/EAST/checkpoints/east/'\n",
    "    idname1 = '20180921-173054'\n",
    "    idname2 = 'model.ckpt-56092'\n",
    "    model_path = checkpoint_path + idname1 + '/' + idname2\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> PWCnet model options >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    nn_opts = deepcopy(_DEFAULT_PWCNET_VAL_OPTIONS)\n",
    "    if FLAGS.flownet_type is 'small':\n",
    "        pwc_cfg = cfg_sm()\n",
    "        pwc_cfg.num_steps = FLAGS.seq_len\n",
    "        nn_opts['use_dense_cx'] = False\n",
    "        nn_opts['use_res_cx'] = False\n",
    "        nn_opts['pyr_lvls'] = 6\n",
    "        nn_opts['flow_pred_lvl'] = 2\n",
    "    else:\n",
    "        pwc_cfg = cfg_lg()\n",
    "        pwc_cfg.num_steps = FLAGS.seq_len\n",
    "        nn_opts['use_dense_cx'] = True\n",
    "        nn_opts['use_res_cx'] = True\n",
    "        nn_opts['pyr_lvls'] = 6\n",
    "        nn_opts['flow_pred_lvl'] = 2\n",
    "    nn_opts['verbose'] = True\n",
    "    nn_opts['ckpt_path'] = pwc_cfg.ckpt_path\n",
    "    nn_opts['batch_size'] = FLAGS.num_steps - 1      # This is Batch_size per GPU\n",
    "    nn_opts['use_tf_data'] = False  # Don't use tf.data reader for this simple task\n",
    "    nn_opts['gpu_devices'] = ['/device:GPU:1']    #\n",
    "    nn_opts['controller'] = '/device:CPU:0'     # Evaluate on CPU or GPU?\n",
    "    nn_opts['adapt_info'] = (1, 436, 1024, 2)\n",
    "    nn_opts['x_shape'] = [2, 512, 512, 3] # image pairs input shape [2, H, W, 3]\n",
    "    nn_opts['y_shape'] = [512, 512, 2] # u,v flows output shape [H, W, 2]\n",
    "    ################################ Model Initialization ############################\n",
    "    # Build the graph\n",
    "    tf.reset_default_graph()\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        batch_size = FLAGS.batch_size_per_gpu * FLAGS.num_gpus\n",
    "        len_seq = FLAGS.num_steps\n",
    "        input_feat_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 32], name='input_feature_maps')\n",
    "        input_flow_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq-1, 128, 128, 2], name='input_flow_maps')\n",
    "        input_score_maps = tf.placeholder(tf.float32, shape=[batch_size , len_seq, 128, 128, 1], name='input_score_maps')\n",
    "#         if FLAGS.geometry == 'RBOX':\n",
    "#             input_geo_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 5], name='input_geo_maps')\n",
    "#         else:\n",
    "#             input_geo_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 8], name='input_geo_maps')\n",
    "#         input_training_masks = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 1], name='input_training_masks'\n",
    "        reuse_variables = None\n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "        score_map_set, geo_map_set = model_gru_agg.build_model(input_feat_maps, input_flow_maps, config=config, reuse_variables=reuse_variables)\n",
    "        config1 = tf.ConfigProto()\n",
    "        config1.gpu_options.allow_growth = True\n",
    "        config1.allow_soft_placement = True\n",
    "        sess1 = tf.Session(config=config1)\n",
    "        # \n",
    "        saver1 = tf.train.Saver(tf.global_variables())\n",
    "        print('continue training from previous checkpoint')\n",
    "        ckpt = FLAGS.prev_checkpoint_path\n",
    "        saver1.restore(sess1, ckpt)\n",
    "    # 2. for PWCnet model \n",
    "    nn = ModelPWCNet(mode='test', options=nn_opts)\n",
    "    # 3. for EAST model \n",
    "    gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "    input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_images')\n",
    "    global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "    score_raw, geometry_raw, feature_raw = model.model(input_images, is_training=False)\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(0.997, global_step)\n",
    "    saver = tf.train.Saver(variable_averages.variables_to_restore())\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    logger.info('Restore from {}'.format(model_path))\n",
    "    saver.restore(sess, model_path)\n",
    "    start = time.time()\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>Start evaluation>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
    "    P_test = []\n",
    "    R_test = []\n",
    "    f1_test= []\n",
    "    index = range(1, len(video_set))\n",
    "    file_txt = save_path + 'eval_gruagg_20181202.txt'\n",
    "    file1 = open(file_txt,\"w+\")\n",
    "    file1.close()\n",
    "    for k in index:\n",
    "        P_video = []\n",
    "        R_video = []\n",
    "        f1_video = []\n",
    "        new_detections = []\n",
    "        video_save = save_path + video_set[k] + idname1 + '_' + idname2 + '.avi'\n",
    "        t_start = time.time()\n",
    "        # sort up all the paths\n",
    "        xml_solo_path = test_data_path + video_set[k]\n",
    "        raw_video_path = test_data_path + video_set[k]+'.mp4'\n",
    "        cap = cv2.VideoCapture(raw_video_path)\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height= int(cap.get(4))\n",
    "        cnt_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print('Now testing '+video_set[k] + ' with %d frames'%(cnt_frame))\n",
    "        out = cv2.VideoWriter(video_save, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "        \n",
    "        # 1. load both polys and tags; 2. generate geo maps(the format of polys and tags need to match)\n",
    "        polys_array_list, tags_array_list, id_list_list, frame_num = load_annotations_solo(xml_solo_path, \\\n",
    "                    1, cnt_frame, frame_width, frame_height)\n",
    "        #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>loop over frames in the time steps, one by one>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        data_original = np.zeros((FLAGS.batch_size_per_gpu, FLAGS.num_steps, frame_height, frame_width, 3))\n",
    "        data_seq = np.zeros((FLAGS.batch_size_per_gpu, FLAGS.num_steps, 512, 512, 3))\n",
    "        for m in range(FLAGS.num_steps):\n",
    "            cap.set(1, m)\n",
    "            ret, frame = cap.read()\n",
    "            im_resized = cv2.resize(frame, (int(512), int(512)))\n",
    "            data_original[0, m, :, :,:] = frame\n",
    "            data_seq[0, m, :, : , :] = im_resized\n",
    "        half_size = int((FLAGS.num_steps- 1)/2)\n",
    "        for i in range(half_size, cnt_frame-half_size):\n",
    "#         for i in range(20, 60):\n",
    "            start = time.time()\n",
    "            cap.set(1, half_size + i)\n",
    "            ret, frame = cap.read()\n",
    "            im_resized = cv2.resize(frame, (int(512), int(512)))\n",
    "            if i>half_size:\n",
    "                data_original[0,0:(FLAGS.seq_len-1), :, :, :] = data_original[0, 1:FLAGS.seq_len, :, :, :]\n",
    "                data_seq[0,0:(FLAGS.seq_len-1), :, :, :] = data_seq[0, 1:FLAGS.seq_len, :, :, :]\n",
    "                data_original[0,FLAGS.seq_len-1, :, :, :] = frame\n",
    "                data_seq[0, FLAGS.seq_len-1, :, :, :] = im_resized\n",
    "            # feed data for east net\n",
    "            east_feed = np.reshape(data_seq, [-1, 512, 512, 3])\n",
    "            ratio_h, ratio_w = 512/frame_height, 512/frame_width\n",
    "            # feed data for flow net \n",
    "            target_frame = np.reshape(np.array(data_seq)[:, 0:4, :, : , :], [-1, 512, 512, 3])\n",
    "            source_frame = np.reshape(np.array(data_seq)[:, 1:5, :, : , :], [-1, 512, 512, 3])\n",
    "            flow_feed = np.concatenate((source_frame[:, np.newaxis, :, :, :], target_frame[:, np.newaxis, :, :, :]), axis = 1)\n",
    "            # >>>>>>>>>>>>>>>>>>>>>>>>>>> feature extraction with EAST >>>>>>>>>>>>>>>>>>>>>>>> #\n",
    "            mini_batch = 5\n",
    "            rounds = int(east_feed.shape[0]/mini_batch)\n",
    "            feature_stack = []\n",
    "            flow_maps_stack = []\n",
    "            score_stack = []\n",
    "            geo_stack = []\n",
    "            for r in range(rounds):\n",
    "                score_map_east, geo_map_east, feature = sess.run([score_raw, geometry_raw, feature_raw],feed_dict={input_images: east_feed[r*mini_batch:(r+1)*mini_batch, :, :, :]})\n",
    "                feature_stack.append(feature)\n",
    "                score_stack.append(score_map_east)\n",
    "                geo_stack.append(geo_map_east)\n",
    "            feature_maps = np.concatenate(feature_stack, axis=0)\n",
    "            feature_maps_reshape = np.reshape(feature_maps, [-1, config.num_steps, 128, 128, 32])\n",
    "#             feature_maps[2, :, :, :] = prev_feature \n",
    "            # score, geo for original east \n",
    "            score_maps = np.concatenate(score_stack, axis=0)\n",
    "            geo_maps = np.concatenate(geo_stack, axis=0)\n",
    "            # >>>>>>>>>>>>>>>>>>>>>>>>>>> flow estimation with PWCnet >>>>>>>>>>>>>>>>>>>>>>>>> #\n",
    "            x_adapt, x_adapt_info = nn.adapt_x(flow_feed)\n",
    "            if x_adapt_info is not None:\n",
    "                y_adapt_info = (x_adapt_info[0], x_adapt_info[2], x_adapt_info[3], 2)\n",
    "            else:\n",
    "                y_adapt_info = None\n",
    "            # Run the adapted samples through the network\n",
    "            mini_batch = nn_opts['batch_size']*nn.num_gpus\n",
    "            rounds = int(flow_feed.shape[0]/mini_batch)\n",
    "            for r in range(rounds):\n",
    "                feed_dict = {nn.x_tnsr: x_adapt[r*mini_batch:(r+1)*mini_batch, :, :, :, :]}\n",
    "                y_hat = nn.sess.run(nn.y_hat_test_tnsr, feed_dict=feed_dict)\n",
    "                y_hats, _ = nn.postproc_y_hat_test(y_hat, y_adapt_info)# suppose to be [batch, height, width, 2]\n",
    "                flow_maps_stack.append(y_hats[:, 1::4, 1::4, :]/4)\n",
    "            flow_maps = np.concatenate(flow_maps_stack, axis=0)\n",
    "            flow_maps = np.reshape(flow_maps, [-1, FLAGS.num_steps-1, 128, 128, 2])\n",
    "            # display_img_pairs_w_flows(img_pairs, pred_labels)\n",
    "            #>>>>>>>>>>>>>>>>>>>>>>>> Generate results with gru-agg model >>>>>>>>>>>>>>>>>>>>\n",
    "            with g.as_default():\n",
    "                geo_results, sco_results = sess1.run([geo_map_set, score_map_set], feed_dict={input_feat_maps:feature_maps_reshape,\n",
    "                                                                  input_flow_maps:flow_maps})\n",
    "            #>>>>>>>>>>>>>>>>>>>>>>>>Okay!!!We could evalute the results now>>>>>>>>>>>>>>>>>>>\n",
    "            #Results refinement via NMS\n",
    "            for t in range(FLAGS.num_steps):\n",
    "                img = data_original[0, t, :, :,:]\n",
    "                f_score = sco_results[t]\n",
    "                f_geometry = geo_results[t]\n",
    "                import pdb;pdb.set_trace()\n",
    "                precision, recall, f1, new_img1 = box_generation(i, img, frame_height, frame_width, f_score, f_geometry, polys_array_list, tags_array_list, start)\n",
    "                print(\"New Model:results on frame {} is P:{}, R{}, F:{}\".format(i, precision, recall, f1))\n",
    "                new_detections.append(new_img1)\n",
    "                P_video.append(precision)\n",
    "                R_video.append(recall)\n",
    "                f1_video.append(f1)\n",
    "                precision_e, recall_e, f1_e, new_img1_e = box_generation(i, img, frame_height, frame_width, score_maps[t][np.newaxis, :, :, :], geo_maps[t][np.newaxis, :, :, :], polys_array_list, tags_array_list, start)\n",
    "                print(\"EAST Model:results on frame {} is P:{}, R{}, F:{}\".format(i, precision_e, recall_e, f1_e))\n",
    "                vis_save_path = save_path + video_set[k] + '/'\n",
    "                if not os.path.exists(vis_save_path):\n",
    "                    os.makedirs(vis_save_path) \n",
    "                import pdb;pdb.set_trace()\n",
    "                if FLAGS.vis:\n",
    "    #                 fig = plt.figure(figsize=(15, 6), dpi=300)\n",
    "    #                 for t in range(FLAGS.seq_len):\n",
    "    #                     ax1 = fig.add_subplot(2, FLAGS.seq_len, t+1, aspect='equal')\n",
    "    #                     ax1.set_title('frame{}'.format(i-mf_ind+t))\n",
    "    #                     plt.axis('off')\n",
    "    #                     ax1.imshow(data_original[0, t, :, :,:].astype(np.uint8))\n",
    "    #                     ax2 = fig.add_subplot(2, FLAGS.seq_len, FLAGS.seq_len+t+1, aspect='equal')\n",
    "    #                     ax2.set_title('score-map{}'.format(i-mf_ind+t))\n",
    "    #                     plt.axis('off')\n",
    "    #                     ax2.imshow((np.squeeze(score_maps[t]*255)).astype(np.uint8)) \n",
    "    #                 fig.savefig(vis_save_path+\"east_frame\" + str(i) + \".png\", dpi=500)\n",
    "                    fig1 = plt.figure(figsize=(8, 8), dpi=300)\n",
    "                    fig1.add_subplot(2, 2, 1, aspect='equal')\n",
    "                    plt.imshow(new_img1_e.astype(np.uint8))\n",
    "                    plt.title('frame {} with EAST'.format(i))\n",
    "                    plt.axis('off')\n",
    "                    fig1.add_subplot(2, 2, 2, aspect='equal')\n",
    "                    plt.imshow(new_img1.astype(np.uint8))\n",
    "                    plt.title('frame {} with New Model'.format(i))\n",
    "                    plt.axis('off')\n",
    "                    fig1.add_subplot(2, 2, 3, aspect='equal')\n",
    "                    plt.imshow((np.squeeze(score_maps[half_size]*255)).astype(np.uint8))\n",
    "                    plt.title('Score map with EAST')\n",
    "                    plt.axis('off')\n",
    "                    fig1.add_subplot(2, 2, 4, aspect='equal')\n",
    "                    plt.imshow((np.squeeze(f_score*255)).astype(np.uint8))\n",
    "                    plt.title('Score Map with New Model')\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "                    fig1.savefig(vis_save_path+\"fuse_frame\" + str(i) + \".png\", dpi=500)\n",
    "            # evaluation on ret and gt\n",
    "            P_test.append(np.array(P_video, dtype=np.float32))\n",
    "            R_test.append(np.array(R_video, dtype=np.float32))\n",
    "            f1_test.append(np.array(f1_video, dtype=np.float32))\n",
    "        print(np.mean(P_video))\n",
    "        print(np.mean(R_video))\n",
    "        print(np.mean(f1_video))\n",
    "#         import pdb;pdb.set_trace()\n",
    "        with open(file_txt, \"a+\") as f:\n",
    "            f.write(video_set[k]+' PRECISION: '+' '.join([\"{:0.6f}\".format(x) for x in P_video])+'\\n')\n",
    "            f.write(video_set[k]+' RECALL: '+' '.join([\"{:0.6f}\".format(x) for x in R_video])+'\\n')\n",
    "            f.write(video_set[k]+' F1 SCORE: '+' '.join([\"{:0.6f}\".format(x) for x in f1_video])+'\\n')\n",
    "        cap.release()\n",
    "    print('here is the precision')\n",
    "    for item in P_test:\n",
    "        print(np.mean(item))\n",
    "    print('here is the recall')\n",
    "    for item in R_test:\n",
    "        print(np.mean(item))\n",
    "    print('here is the f-score')\n",
    "    for item in f1_test:\n",
    "        print(np.mean(item))\n",
    "    print(video_set)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
