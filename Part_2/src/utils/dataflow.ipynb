{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "from abc import abstractmethod\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpack import ModelDesc\n",
    "from tensorpack.dataflow import AugmentImageComponent, BatchData, MultiThreadMapData, PrefetchDataZMQ, dataset, imgaug\n",
    "from tensorpack.input_source import QueueInput, StagingInput\n",
    "from tensorpack.models import regularize_cost\n",
    "from tensorpack.predict import FeedfreePredictor, PredictConfig\n",
    "from tensorpack.tfutils.summary import add_moving_summary\n",
    "from tensorpack.utils import logger\n",
    "from tensorpack.utils.stats import RatioCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A minimum example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def my_data_loader():\n",
    "#   # load data from somewhere with Python, and yield them\n",
    "#   for k in range(100):\n",
    "#     yield [my_array, my_label]\n",
    "\n",
    "# df = DataFromGenerator(my_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6\n",
      "\n",
      "5\n",
      "\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# a DataFlow you implement to produce [tensor1, tensor2, ..] lists from whatever sources:\n",
    "from tensorpack import DataFlow, DataFromGenerator\n",
    "from tensorpack.dataflow.parallel import PlasmaGetData, PlasmaPutData  # noqa\n",
    "class MyDataFlow(DataFlow):\n",
    "  def __iter__(self):\n",
    "    # load data from somewhere with Python, and yield them\n",
    "#     ds = PrintData(ds, num=2, max_list=2)\n",
    " \n",
    "    for k in range(10):\n",
    "      digit = np.random.rand(2, 2)\n",
    "      label = np.random.randint(10)\n",
    "      yield [digit, label]\n",
    "      \n",
    "df = MyDataFlow()\n",
    "df = BatchData(df, 3)\n",
    "# df = PlasmaGetData(df)\n",
    "df.reset_state()\n",
    "for datapoint in df:\n",
    "    \n",
    "    print(\"\")\n",
    "    print(datapoint[1][0])\n",
    "# print(df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A higher level demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0106 15:21:52 @parallel.py:311]\u001b[0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n",
      "\u001b[32m[0106 15:21:52 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n",
      "data loader preparation costs 2.1918246746063232 seconds\n",
      "now passed 34.47462201118469 seconds\n",
      "now passed 42.04209542274475 seconds\n",
      "now passed 42.729400396347046 seconds\n",
      "now passed 43.465091943740845 seconds\n",
      "now passed 44.5822970867157 seconds\n",
      "now passed 44.81189441680908 seconds\n",
      "now passed 47.75291585922241 seconds\n",
      "now passed 48.540337800979614 seconds\n",
      "now passed 48.86101245880127 seconds\n",
      "now passed 49.04390048980713 seconds\n",
      "now passed 49.817816495895386 seconds\n",
      "now passed 49.99043846130371 seconds\n",
      "now passed 50.406837463378906 seconds\n",
      "now passed 50.50053524971008 seconds\n",
      "now passed 50.67884349822998 seconds\n",
      "now passed 51.746458292007446 seconds\n",
      "now passed 84.2175965309143 seconds\n",
      "now passed 84.38138175010681 seconds\n",
      "now passed 84.87508749961853 seconds\n",
      "now passed 84.99437308311462 seconds\n",
      "now passed 87.99221873283386 seconds\n",
      "now passed 88.20371890068054 seconds\n",
      "now passed 89.4891607761383 seconds\n",
      "now passed 91.71360230445862 seconds\n",
      "now passed 91.94022011756897 seconds\n",
      "now passed 92.04336857795715 seconds\n",
      "now passed 93.02071022987366 seconds\n",
      "now passed 93.10678386688232 seconds\n",
      "now passed 95.27450609207153 seconds\n",
      "now passed 97.27386832237244 seconds\n",
      "now passed 97.77041745185852 seconds\n",
      "now passed 98.89172768592834 seconds\n",
      "now passed 119.00615930557251 seconds\n",
      "now passed 123.47625875473022 seconds\n",
      "now passed 127.22830319404602 seconds\n",
      "now passed 127.98968029022217 seconds\n",
      "now passed 130.50795030593872 seconds\n",
      "now passed 131.07101941108704 seconds\n",
      "now passed 131.42911911010742 seconds\n",
      "now passed 132.71184659004211 seconds\n",
      "now passed 133.5235619544983 seconds\n",
      "now passed 135.02772331237793 seconds\n",
      "now passed 137.66006660461426 seconds\n",
      "now passed 137.75736498832703 seconds\n",
      "now passed 138.18121886253357 seconds\n",
      "now passed 140.13122701644897 seconds\n",
      "now passed 147.06232333183289 seconds\n",
      "now passed 148.20523643493652 seconds\n",
      "now passed 166.4275197982788 seconds\n",
      "now passed 174.89421772956848 seconds\n",
      "now passed 175.09622740745544 seconds\n",
      "now passed 175.41403436660767 seconds\n",
      "now passed 175.895085811615 seconds\n",
      "now passed 178.1699035167694 seconds\n",
      "now passed 179.20454216003418 seconds\n",
      "now passed 180.48681640625 seconds\n",
      "now passed 180.67500805854797 seconds\n",
      "now passed 182.58075714111328 seconds\n",
      "now passed 183.27638697624207 seconds\n",
      "now passed 183.49975657463074 seconds\n",
      "now passed 187.3947913646698 seconds\n",
      "now passed 187.72993755340576 seconds\n",
      "now passed 188.50012755393982 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from time import time\n",
    "from random import randint\n",
    "from icdar_smart import load_annotations_solo, check_and_validate_polys\n",
    "from tensorpack import DataFlow, DataFromGenerator\n",
    "from tensorpack.dataflow.parallel import PlasmaGetData, PlasmaPutData  # noqa\n",
    "# a DataFlow you implement to produce [tensor1, tensor2, ..] lists from whatever sources:\n",
    "ICDAR2013 = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/'\n",
    "video_dir = ICDAR2013+'/train/'\n",
    "# we may not need to process \n",
    "data_dir = '/work/cascades/lxiaol9/ARC/EAST/data/pre-processed/'\n",
    "\n",
    "def crop_all_random_seq(num_steps, data, score_maps, geo_maps, training_masks, crop_background=False, max_tries=20):\n",
    "    '''\n",
    "    make random crop from the input image\n",
    "    :param im:\n",
    "    :param polys:\n",
    "    :param tags:\n",
    "    :param crop_background:\n",
    "    :param max_tries:\n",
    "    :return:\n",
    "    '''\n",
    "    # crop and assemble\n",
    "    score_map = score_maps[0, :, :]\n",
    "    flag = False # indication of success\n",
    "    input_size = 512\n",
    "    px_size = 512 # real patch size\n",
    "    py_size = 512 # real patch size\n",
    "    frame_height, frame_width = score_map.shape\n",
    "    if frame_height < 512:\n",
    "        # for i in range(max_tries*15):\n",
    "        images_new = np.zeros((num_steps, input_size, input_size, 3), dtype=np.uint8)\n",
    "        scores_new = np.zeros((num_steps, input_size, input_size), dtype=np.uint8)\n",
    "        geos_new = np.zeros((num_steps, input_size, input_size, 5), dtype=np.float32)\n",
    "        tmasks_new = np.ones((num_steps, input_size, input_size), dtype=np.uint8)\n",
    "        x = 0\n",
    "        y = randint(2, frame_width-py_size-5)\n",
    "            # print(\"Iterating over max_tries*15, {}\".format(i))\n",
    "            # if (sum(sum(score_map[:, y-2:y+3])) + sum(sum(score_map[:, y+py_size-2:y+py_size+3]))) == 0:\n",
    "        flag = True\n",
    "        images_new[:, :frame_height, :py_size, :] = data[:, :, y:y+py_size, :]\n",
    "        scores_new[:, :frame_height, :py_size] = score_maps[:, :, y:y+py_size]\n",
    "        geos_new[:, :frame_height, :py_size, :]= geo_maps[:, :, y:y+py_size, :]\n",
    "        tmasks_new[:, :frame_height, :py_size] = training_masks[:, :, y:y+py_size]\n",
    "        return images_new, scores_new, geos_new, tmasks_new\n",
    "    else:\n",
    "        new_h, new_w = frame_height, frame_width\n",
    "        attempt_cnt = 0\n",
    "        while attempt_cnt<max_tries:\n",
    "            py_size = 512\n",
    "            x = randint(2, new_h-px_size-5)\n",
    "            y = randint(2, new_w-py_size-5)\n",
    "            if score_map[x, y] > 0:\n",
    "                continue\n",
    "            attempt_cnt +=1\n",
    "            return data[:, x:x+px_size, y:y+py_size, :], score_maps[:, x:x+px_size, y:y+py_size], geo_maps[:, x:x+px_size, y:y+py_size],  training_masks[:, x:x+px_size, y:y+py_size]\n",
    "    # print('Cropping failed, change the strategy!!!')\n",
    "    return None, None, None, None\n",
    "\n",
    "# preprocessing function\n",
    "class data_raw():\n",
    "    def __init__(self, video_dir, datapre_path, is_print=False):\n",
    "        self.video_set = []\n",
    "        self.video_dir = video_dir\n",
    "        self.datapre_path = datapre_path\n",
    "        for root, dirs, files in os.walk(video_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.mp4'):\n",
    "                    cap = cv2.VideoCapture(video_dir+file)\n",
    "                    b = {}\n",
    "                    b[\"video_name\"]   = os.path.splitext(file)[0]\n",
    "                    b[\"frame_width\"]  = int(cap.get(3))\n",
    "                    b[\"frame_height\"] = int(cap.get(4))\n",
    "                    b[\"frame_num\"]    = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    xml_solo_path = video_dir + b[\"video_name\"]\n",
    "                    polys_array_list, tags_array_list, _, _ = load_annotations_solo(xml_solo_path, 1,\\\n",
    "                                                                                  b[\"frame_num\"])\n",
    "                    b[\"polys_list\"]   = polys_array_list\n",
    "                    b[\"tags_list\"]    = tags_array_list\n",
    "                    self.video_set.append(b)\n",
    "                    cap.release()\n",
    "        self.total_num = len(self.video_set)\n",
    "        if is_print:\n",
    "            for i in range(self.total_num):\n",
    "                print(\"{} with {} frames of w:{}, h:{}, polys of the first frame: {}, and tags: {}\\n\".format(\n",
    "                                                self.video_set[i][\"video_name\"], \n",
    "                                                self.video_set[i][\"frame_num\"], \n",
    "                                                self.video_set[i][\"frame_width\"],\n",
    "                                                self.video_set[i][\"frame_height\"],\n",
    "                                                self.video_set[i][\"polys_list\"][0],\n",
    "                                                self.video_set[i][\"tags_list\"][0]\n",
    "                )\n",
    "                     )\n",
    "          \n",
    "class MyDataFlow(DataFlow):\n",
    "    def __init__(self, raw_data, num_steps, is_training):\n",
    "        super(MyDataFlow, self).__init__()\n",
    "        self.raw_data = raw_data\n",
    "        self.num_steps = num_steps\n",
    "        self.is_training = is_training\n",
    "    def __iter__(self):\n",
    "        raw_data =  self.raw_data \n",
    "        datapre_path = raw_data.datapre_path\n",
    "        num_steps   = self.num_steps \n",
    "        is_training = self.is_training  \n",
    "        if is_training:\n",
    "            for k in range(100):\n",
    "                i = randint(0, raw_data.total_num-3-1)\n",
    "                j = randint(0, raw_data.video_set[i][\"frame_num\"] - num_steps -1)  \n",
    "                new_h, new_w = raw_data.video_set[i][\"frame_height\"], raw_data.video_set[i][\"frame_width\"]\n",
    "                # pre_data\n",
    "                images = np.zeros([num_steps, new_h, new_w, 3], dtype=np.uint8)\n",
    "                score_maps = np.zeros([num_steps, new_h, new_w], dtype=np.uint8)\n",
    "                geo_maps = np.zeros([num_steps, new_h, new_w, 5], dtype=np.float32)\n",
    "                training_masks = np.ones([num_steps, new_h, new_w], dtype=np.uint8)\n",
    "                cap = cv2.VideoCapture(raw_data.video_dir+ raw_data.video_set[i][\"video_name\"] + '.mp4')\n",
    "                for m in range(num_steps):\n",
    "                    cap.set(1, j+m)\n",
    "                    ret, image = cap.read()\n",
    "                    text_polys, text_tags = raw_data.video_set[i][\"polys_list\"][j+m], \\\n",
    "                                            raw_data.video_set[i][\"tags_list\"][j+m]\n",
    "                    text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (new_h, new_w))\n",
    "                    if text_polys.shape[0] == 0:# means no boxes here\n",
    "                        images[m, :, :, :] = image\n",
    "                        continue\n",
    "                    # load pre-processed data\n",
    "                    score_name = datapre_path + 'score_maps/' + '{}'.format(raw_data.video_set[i][\"video_name\"])+ '/frame'+'{:04d}'.format(j+m)+'.npy'\n",
    "                    geo_name = datapre_path + 'geo_maps/' + '{}'.format(raw_data.video_set[i][\"video_name\"])+'/frame'+'{:04d}'.format(j+m)+'.npy'\n",
    "                    mask_name = datapre_path + 'training_masks/' + '{}'.format(raw_data.video_set[i][\"video_name\"])+'/frame'+'{:04d}'.format(j+m)+'.npy'\n",
    "                    images[m, :, :, :]    = image\n",
    "                    score_maps[m, :, :] = np.load(score_name)\n",
    "                    geo_maps[m, :, :, :] = np.load(geo_name)\n",
    "                    training_masks[m, :, :] = np.load(mask_name) \n",
    "                cap.release()\n",
    "                imgs_c, score_maps_c, geo_maps_c, training_masks_c = crop_all_random_seq(num_steps, images, score_maps, geo_maps, training_masks)\n",
    "#                 if if imgs_c is not None\n",
    "                yield [imgs_c, score_maps_c, geo_maps_c, training_masks_c]\n",
    "t1_start = time()\n",
    "dr = data_raw(video_dir, data_dir, is_print=False)      \n",
    "df = MyDataFlow(raw_data=dr, num_steps=5, is_training=True)\n",
    "df = BatchData(df, 16)\n",
    "df = PrefetchDataZMQ(df, 16)\n",
    "# df = PlasmaGetData(df)\n",
    "df.reset_state()\n",
    "t1_end = time()\n",
    "print(\"data loader preparation costs {} seconds\".format(t1_end - t1_start))\n",
    "for datapoint in df:\n",
    "    print(\"now passed {} seconds\".format(time() - t1_end))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_orig(dir, name, augs, batch):\n",
    "    ds = dataset.ILSVRC12(dir, name, shuffle=True)\n",
    "    ds = AugmentImageComponent(ds, augs)\n",
    "\n",
    "    ds = BatchData(ds, batch)\n",
    "    # ds = PlasmaPutData(ds)\n",
    "    ds = PrefetchDataZMQ(ds, 50, hwm=80)\n",
    "    return ds\n",
    "\n",
    "def test_lmdb_train(db, augs, batch):\n",
    "    ds = LMDBData(db, shuffle=False)\n",
    "    ds = LocallyShuffleData(ds, 50000)\n",
    "    ds = PrefetchData(ds, 5000, 1)\n",
    "    return ds\n",
    "\n",
    "    ds = LMDBDataPoint(ds)\n",
    "\n",
    "    def f(x):\n",
    "        return cv2.imdecode(x, cv2.IMREAD_COLOR)\n",
    "    ds = MapDataComponent(ds, f, 0)\n",
    "    ds = AugmentImageComponent(ds, augs)\n",
    "\n",
    "    ds = BatchData(ds, batch, use_list=True)\n",
    "    # ds = PlasmaPutData(ds)\n",
    "    ds = PrefetchDataZMQ(ds, 40, hwm=80)\n",
    "    # ds = PlasmaGetData(ds)\n",
    "    return ds\n",
    "\n",
    "def test_inference(dir, name, augs, batch=128):\n",
    "    ds = dataset.ILSVRC12Files(dir, name, shuffle=False, dir_structure='train')\n",
    "\n",
    "    aug = imgaug.AugmentorList(augs)\n",
    "\n",
    "    def mapf(dp):\n",
    "        fname, cls = dp\n",
    "        im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "        im = aug.augment(im)\n",
    "        return im, cls\n",
    "    ds = ThreadedMapData(ds, 30, mapf, buffer_size=2000, strict=True)\n",
    "    ds = BatchData(ds, batch)\n",
    "    ds = PrefetchDataZMQ(ds, 1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataFlow(DataFlow):\n",
    "  def __iter__(self, dir):\n",
    "    # load data from somewhere with Python, and yield them\n",
    "    video_set = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp4'):\n",
    "                video_set.append(os.path.splitext(file)[0])\n",
    "                \n",
    "      yield [digit, label]\n",
    "    \n",
    "class ProcessingDataFlow(DataFlow):\n",
    "  def __init__(self, ds):\n",
    "    self.ds = ds\n",
    "    \n",
    "  def reset_state(self):\n",
    "    self.ds.reset_state()\n",
    "\n",
    "  def __iter__(self):\n",
    "    for datapoint in self.ds:\n",
    "      # do something\n",
    "      yield new_datapoint\n",
    "# df = MyDataFlow()\n",
    "# df.reset_state()\n",
    "# for datapoint in df:\n",
    "#     print(datapoint[0], datapoint[1]\n",
    "df = MyDataFlow(dir='/my/data', shuffle=True)\n",
    "# resize the image component of each datapoint\n",
    "df = AugmentImageComponent(df, [imgaug.Resize((225, 225))])\n",
    "# group data into batches of size 128\n",
    "df = BatchData(df, 128)\n",
    "# start 3 processes to run the dataflow in parallel\n",
    "df = PrefetchDataZMQ(df, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
