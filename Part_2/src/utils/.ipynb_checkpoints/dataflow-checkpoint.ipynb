{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "from abc import abstractmethod\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorpack import ModelDesc\n",
    "from tensorpack.dataflow import AugmentImageComponent, BatchData, MultiThreadMapData, PrefetchDataZMQ, dataset, imgaug\n",
    "from tensorpack.input_source import QueueInput, StagingInput\n",
    "from tensorpack.models import regularize_cost\n",
    "from tensorpack.predict import FeedfreePredictor, PredictConfig\n",
    "from tensorpack.tfutils.summary import add_moving_summary\n",
    "from tensorpack.utils import logger\n",
    "from tensorpack.utils.stats import RatioCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A minimum example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def my_data_loader():\n",
    "#   # load data from somewhere with Python, and yield them\n",
    "#   for k in range(100):\n",
    "#     yield [my_array, my_label]\n",
    "\n",
    "# df = DataFromGenerator(my_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6\n",
      "\n",
      "5\n",
      "\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# a DataFlow you implement to produce [tensor1, tensor2, ..] lists from whatever sources:\n",
    "from tensorpack import DataFlow, DataFromGenerator\n",
    "from tensorpack.dataflow.parallel import PlasmaGetData, PlasmaPutData  # noqa\n",
    "class MyDataFlow(DataFlow):\n",
    "  def __iter__(self):\n",
    "    # load data from somewhere with Python, and yield them\n",
    "#     ds = PrintData(ds, num=2, max_list=2)\n",
    " \n",
    "    for k in range(10):\n",
    "      digit = np.random.rand(2, 2)\n",
    "      label = np.random.randint(10)\n",
    "      yield [digit, label]\n",
    "      \n",
    "df = MyDataFlow()\n",
    "df = BatchData(df, 3)\n",
    "# df = PlasmaGetData(df)\n",
    "df.reset_state()\n",
    "for datapoint in df:\n",
    "    \n",
    "    print(\"\")\n",
    "    print(datapoint[1][0])\n",
    "# print(df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A higher level demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0106 15:05:51 @common.py:142]\u001b[0m \u001b[4m\u001b[5m\u001b[31mERR\u001b[0m Cannot batch data. Perhaps they are of inconsistent shape?\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorpack/dataflow/common.py\", line 140, in _batch_numpy\n",
      "    return np.asarray(data_list, dtype=dtype)\n",
      "  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/numpy/core/numeric.py\", line 492, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "ValueError: could not broadcast input array from shape (5,720,1280,3) into shape (5)\n",
      "\u001b[32m[0106 15:05:51 @common.py:145]\u001b[0m \u001b[4m\u001b[5m\u001b[31mERR\u001b[0m Shape of all arrays to be batched: [(5, 720, 1280, 3), (5, 960, 1280, 3), (5, 720, 1280, 3)]\n",
      "Python 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) \n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from random import randint\n",
    "from icdar_smart import load_annotations_solo, check_and_validate_polys\n",
    "from tensorpack import DataFlow, DataFromGenerator\n",
    "from tensorpack.dataflow.parallel import PlasmaGetData, PlasmaPutData  # noqa\n",
    "# a DataFlow you implement to produce [tensor1, tensor2, ..] lists from whatever sources:\n",
    "ICDAR2013 = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/'\n",
    "video_dir = ICDAR2013+'/train/'\n",
    "# we may not need to process \n",
    "data_dir = '/work/cascades/lxiaol9/ARC/EAST/data/pre-processed/'\n",
    "\n",
    "def crop_all_random_seq(num_steps, data, score_maps, geo_maps, training_masks, crop_background=False, max_tries=20):\n",
    "    '''\n",
    "    make random crop from the input image\n",
    "    :param im:\n",
    "    :param polys:\n",
    "    :param tags:\n",
    "    :param crop_background:\n",
    "    :param max_tries:\n",
    "    :return:\n",
    "    '''\n",
    "    # crop and assemble\n",
    "    score_map = score_maps[0, :, :]\n",
    "    flag = False # indication of success\n",
    "    input_size = 512\n",
    "    px_size = 512 # real patch size\n",
    "    py_size = 512 # real patch size\n",
    "    frame_height, frame_width = score_map.shape\n",
    "    if frame_height < 512:\n",
    "        # for i in range(max_tries*15):\n",
    "        images_new = np.zeros((num_steps, input_size, input_size, 3), dtype=np.uint8)\n",
    "        scores_new = np.zeros((num_steps, input_size, input_size), dtype=np.uint8)\n",
    "        geos_new = np.zeros((num_steps, input_size, input_size, 5), dtype=np.float32)\n",
    "        tmasks_new = np.ones((num_steps, input_size, input_size), dtype=np.uint8)\n",
    "        x = 0\n",
    "        y = randint(2, frame_width-py_size-5)\n",
    "            # print(\"Iterating over max_tries*15, {}\".format(i))\n",
    "            # if (sum(sum(score_map[:, y-2:y+3])) + sum(sum(score_map[:, y+py_size-2:y+py_size+3]))) == 0:\n",
    "        flag = True\n",
    "        images_new[:, :frame_height, :py_size, :] = data[:, :, y:y+py_size, :]\n",
    "        scores_new[:, :frame_height, :py_size] = score_maps[:, :, y:y+py_size]\n",
    "        geos_new[:, :frame_height, :py_size, :]= geo_maps[:, :, y:y+py_size, :]\n",
    "        tmasks_new[:, :frame_height, :py_size] = training_masks[:, :, y:y+py_size]\n",
    "        return images_new, scores_new, geos_new, tmasks_new\n",
    "    else:\n",
    "        new_h, new_w = frame_height, frame_width\n",
    "        attempt_cnt = 0\n",
    "        while attempt_cnt<max_tries:\n",
    "            py_size = 512\n",
    "            x = randint(2, new_h-px_size-5)\n",
    "            y = randint(2, new_w-py_size-5)\n",
    "            if score_map[x, y] > 0:\n",
    "                continue\n",
    "            attempt_cnt +=1\n",
    "            return data[:, x:x+px_size, y:y+py_size, :], score_maps[:, x:x+px_size, y:y+py_size], geo_maps[:, x:x+px_size, y:y+py_size],  training_masks[:, x:x+px_size, y:y+py_size]\n",
    "    # print('Cropping failed, change the strategy!!!')\n",
    "    return None, None, None, None\n",
    "\n",
    "# preprocessing function\n",
    "class data_raw():\n",
    "    def __init__(self, video_dir, datapre_path, is_print=False):\n",
    "        self.video_set = []\n",
    "        self.video_dir = video_dir\n",
    "        self.datapre_path = datapre_path\n",
    "        for root, dirs, files in os.walk(video_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.mp4'):\n",
    "                    cap = cv2.VideoCapture(video_dir+file)\n",
    "                    b = {}\n",
    "                    b[\"video_name\"]   = os.path.splitext(file)[0]\n",
    "                    b[\"frame_width\"]  = int(cap.get(3))\n",
    "                    b[\"frame_height\"] = int(cap.get(4))\n",
    "                    b[\"frame_num\"]    = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    xml_solo_path = video_dir + b[\"video_name\"]\n",
    "                    polys_array_list, tags_array_list, _, _ = load_annotations_solo(xml_solo_path, 1,\\\n",
    "                                                                                  b[\"frame_num\"])\n",
    "                    b[\"polys_list\"]   = polys_array_list\n",
    "                    b[\"tags_list\"]    = tags_array_list\n",
    "                    self.video_set.append(b)\n",
    "                    cap.release()\n",
    "        self.total_num = len(self.video_set)\n",
    "        if is_print:\n",
    "            for i in range(self.total_num):\n",
    "                print(\"{} with {} frames of w:{}, h:{}, polys of the first frame: {}, and tags: {}\\n\".format(\n",
    "                                                self.video_set[i][\"video_name\"], \n",
    "                                                self.video_set[i][\"frame_num\"], \n",
    "                                                self.video_set[i][\"frame_width\"],\n",
    "                                                self.video_set[i][\"frame_height\"],\n",
    "                                                self.video_set[i][\"polys_list\"][0],\n",
    "                                                self.video_set[i][\"tags_list\"][0]\n",
    "                )\n",
    "                     )\n",
    "          \n",
    "class MyDataFlow(DataFlow):\n",
    "    def __init__(self, raw_data, num_steps, is_training):\n",
    "        super(MyDataFlow, self).__init__()\n",
    "        self.raw_data = raw_data\n",
    "        self.num_steps = num_steps\n",
    "        self.is_training = is_training\n",
    "    def __iter__(self):\n",
    "        raw_data =  self.raw_data \n",
    "        datapre_path = raw_data.datapre_path\n",
    "        num_steps   = self.num_steps \n",
    "        is_training = self.is_training  \n",
    "        if is_training:\n",
    "            for k in range(100):\n",
    "                i = randint(0, raw_data.total_num-3-1)\n",
    "                j = randint(0, raw_data.video_set[i][\"frame_num\"] - num_steps -1)  \n",
    "                new_h, new_w = raw_data.video_set[i][\"frame_height\"], raw_data.video_set[i][\"frame_width\"]\n",
    "                # pre_data\n",
    "                images = np.zeros([num_steps, new_h, new_w, 3], dtype=np.uint8)\n",
    "                score_maps = np.zeros([num_steps, new_h, new_w], dtype=np.uint8)\n",
    "                geo_maps = np.zeros([num_steps, new_h, new_w, 5], dtype=np.float32)\n",
    "                training_masks = np.ones([num_steps, new_h, new_w], dtype=np.uint8)\n",
    "                cap = cv2.VideoCapture(raw_data.video_dir+ raw_data.video_set[i][\"video_name\"] + '.mp4')\n",
    "                for m in range(num_steps):\n",
    "                    cap.set(1, j+m)\n",
    "                    ret, image = cap.read()\n",
    "                    text_polys, text_tags = raw_data.video_set[i][\"polys_list\"][j+m], \\\n",
    "                                            raw_data.video_set[i][\"tags_list\"][j+m]\n",
    "                    text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (new_h, new_w))\n",
    "                    if text_polys.shape[0] == 0:# means no boxes here\n",
    "                        images[m, :, :, :] = image\n",
    "                        continue\n",
    "                    # load pre-processed data\n",
    "                    score_name = datapre_path + 'score_maps/' + '{}'.format(raw_data.video_set[i][\"video_name\"])+ '/frame'+'{:04d}'.format(j+m)+'.npy'\n",
    "                    geo_name = datapre_path + 'geo_maps/' + '{}'.format(raw_data.video_set[i][\"video_name\"])+'/frame'+'{:04d}'.format(j+m)+'.npy'\n",
    "                    mask_name = datapre_path + 'training_masks/' + '{}'.format(raw_data.video_set[i][\"video_name\"])+'/frame'+'{:04d}'.format(j+m)+'.npy'\n",
    "                    images[m, :, :, :]    = image\n",
    "                    score_maps[m, :, :] = np.load(score_name)\n",
    "                    geo_maps[m, :, :, :] = np.load(geo_name)\n",
    "                    training_masks[m, :, :] = np.load(mask_name) \n",
    "                cap.release()\n",
    "                imgs_c, score_maps_c, geo_maps_c, training_masks_c = crop_all_random_seq(num_steps, data, score_maps, geo_maps, training_masks)\n",
    "                \n",
    "                yield [images, score_maps, geo_maps, training_masks]\n",
    "dr = data_raw(video_dir, data_dir, is_print=False)      \n",
    "df = MyDataFlow(raw_data=dr, num_steps=5, is_training=True)\n",
    "df = BatchData(df, 3)\n",
    "# df = PlasmaGetData(df)\n",
    "df.reset_state()\n",
    "for datapoint in df:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_orig(dir, name, augs, batch):\n",
    "    ds = dataset.ILSVRC12(dir, name, shuffle=True)\n",
    "    ds = AugmentImageComponent(ds, augs)\n",
    "\n",
    "    ds = BatchData(ds, batch)\n",
    "    # ds = PlasmaPutData(ds)\n",
    "    ds = PrefetchDataZMQ(ds, 50, hwm=80)\n",
    "    return ds\n",
    "\n",
    "def test_lmdb_train(db, augs, batch):\n",
    "    ds = LMDBData(db, shuffle=False)\n",
    "    ds = LocallyShuffleData(ds, 50000)\n",
    "    ds = PrefetchData(ds, 5000, 1)\n",
    "    return ds\n",
    "\n",
    "    ds = LMDBDataPoint(ds)\n",
    "\n",
    "    def f(x):\n",
    "        return cv2.imdecode(x, cv2.IMREAD_COLOR)\n",
    "    ds = MapDataComponent(ds, f, 0)\n",
    "    ds = AugmentImageComponent(ds, augs)\n",
    "\n",
    "    ds = BatchData(ds, batch, use_list=True)\n",
    "    # ds = PlasmaPutData(ds)\n",
    "    ds = PrefetchDataZMQ(ds, 40, hwm=80)\n",
    "    # ds = PlasmaGetData(ds)\n",
    "    return ds\n",
    "\n",
    "def test_inference(dir, name, augs, batch=128):\n",
    "    ds = dataset.ILSVRC12Files(dir, name, shuffle=False, dir_structure='train')\n",
    "\n",
    "    aug = imgaug.AugmentorList(augs)\n",
    "\n",
    "    def mapf(dp):\n",
    "        fname, cls = dp\n",
    "        im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "        im = aug.augment(im)\n",
    "        return im, cls\n",
    "    ds = ThreadedMapData(ds, 30, mapf, buffer_size=2000, strict=True)\n",
    "    ds = BatchData(ds, batch)\n",
    "    ds = PrefetchDataZMQ(ds, 1)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataFlow(DataFlow):\n",
    "  def __iter__(self, dir):\n",
    "    # load data from somewhere with Python, and yield them\n",
    "    video_set = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp4'):\n",
    "                video_set.append(os.path.splitext(file)[0])\n",
    "                \n",
    "      yield [digit, label]\n",
    "    \n",
    "class ProcessingDataFlow(DataFlow):\n",
    "  def __init__(self, ds):\n",
    "    self.ds = ds\n",
    "    \n",
    "  def reset_state(self):\n",
    "    self.ds.reset_state()\n",
    "\n",
    "  def __iter__(self):\n",
    "    for datapoint in self.ds:\n",
    "      # do something\n",
    "      yield new_datapoint\n",
    "# df = MyDataFlow()\n",
    "# df.reset_state()\n",
    "# for datapoint in df:\n",
    "#     print(datapoint[0], datapoint[1]\n",
    "df = MyDataFlow(dir='/my/data', shuffle=True)\n",
    "# resize the image component of each datapoint\n",
    "df = AugmentImageComponent(df, [imgaug.Resize((225, 225))])\n",
    "# group data into batches of size 128\n",
    "df = BatchData(df, 128)\n",
    "# start 3 processes to run the dataflow in parallel\n",
    "df = PrefetchDataZMQ(df, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
