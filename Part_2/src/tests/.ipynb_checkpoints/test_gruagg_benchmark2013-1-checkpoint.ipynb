{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##===================== Statements & Copyright ===================##\n",
    "\"\"\"\n",
    "AUTHOR:  Xiaolong Li, VT\n",
    "CONTENT: Used for Video-text project\n",
    "LOG:     add code for agg model \n",
    "\"\"\"\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import platform\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import slim\n",
    "import sys\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "\n",
    "import _init_paths\n",
    "from model import model\n",
    "from model import model_flow_east\n",
    "from pwc.dataset_base import _DEFAULT_DS_VAL_OPTIONS\n",
    "from pwc.model_pwcnet import ModelPWCNet, _DEFAULT_PWCNET_VAL_OPTIONS\n",
    "from pwc.net_options import cfg_lg, cfg_sm\n",
    "from config.configrnn import get_config\n",
    "from model.model_aggregation import Aggregation\n",
    "from lstm import model_gru_concat model_gru_agg\n",
    "from utils.icdar import restore_rectangle\n",
    "import lanms\n",
    "from utils.eval import resize_image, sort_poly, detect\n",
    "from utils.icdar import load_annotations_solo, check_and_validate_polys\n",
    "from utils.nms_highlevel import intersection\n",
    "import matplotlib.pyplot as plt\n",
    "now = datetime.now()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "# used for iou searching and selecting TP, FP, FN #\n",
    "def eval_single_frame(target, box):\n",
    "    \"\"\"\n",
    "    input params:\n",
    "        target, python ordered dict\n",
    "        box, sorted boxes dict from predictions\n",
    "    \"\"\"\n",
    "    TP   = 0\n",
    "    FP   = 0\n",
    "    FN   = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    F_measure = 0\n",
    "    if not len(box['text_lines']) == 0:\n",
    "        for t in target:\n",
    "            d = np.array(t, dtype='int32')\n",
    "            is_best = 0\n",
    "            for m in box['text_lines']:\n",
    "                n = np.array([m['x0'], m['y0'], m['x1'], m['y1'], m['x2'],\n",
    "                              m['y2'], m['x3'], m['y3']], dtype='int32')\n",
    "\n",
    "                # pick out the best match\n",
    "                iou = intersection(n, d)\n",
    "                if iou>is_best:\n",
    "                    is_best = iou\n",
    "            if is_best > 0.5:\n",
    "                TP = TP+1\n",
    "            elif is_best == 0:\n",
    "                FN = FN +1\n",
    "            else:\n",
    "                FP = FP+1\n",
    "        if TP > 0:\n",
    "            precision = TP/(TP+FP)\n",
    "            recall    = TP/(TP+FN)\n",
    "            F_measure = 2*precision*recall/(precision+recall)\n",
    "#     if len(target) == 0:\n",
    "#         precision = 1\n",
    "#         recall    = 1\n",
    "#         F_measure = 1\n",
    "    return precision, recall, F_measure\n",
    "\n",
    "\n",
    "def draw_illu(illu, rst):\n",
    "    for t in rst['text_lines']:\n",
    "        d = np.array([t['x0'], t['y0'], t['x1'], t['y1'], t['x2'],\n",
    "                      t['y2'], t['x3'], t['y3']], dtype='int32')\n",
    "        d = d.reshape(-1, 2)\n",
    "        cv2.polylines(illu, [d], isClosed=True, thickness=2, color=(255, 0, 0))\n",
    "    return illu\n",
    "\n",
    "\n",
    "def draw_illu_gt(illu, rst, p, r, f):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.3\n",
    "    fontColor = (255, 255, 255)\n",
    "    lineType = 1\n",
    "    infos = 'Precision ' + str(p)+ ', recall ' + str(r) + ', F_measure ' + str(f)\n",
    "    cv2.putText(illu, infos,\n",
    "                (2, 20),\n",
    "                font,\n",
    "                0.5,\n",
    "                (255, 0, 0),\n",
    "                lineType)\n",
    "    for t in rst:\n",
    "        d1 = t.reshape(-1, 2).astype(np.int32)\n",
    "        cv2.polylines(illu, [d1], isClosed=True, thickness=2, color=(0, 0, 0))\n",
    "        # bottomLeftCornerOfText = (int(t['x0']), int(t['y0']))\n",
    "\n",
    "    return illu\n",
    "\n",
    "\n",
    "def box_generation(index, img, frame_height, frame_width, f_score, f_geometry, polys_array_list, tags_array_list, start):\n",
    "    timer = collections.OrderedDict([\n",
    "                        ('net', 0),\n",
    "                        ('restore', 0),\n",
    "                        ('nms', 0)\n",
    "                                   ])\n",
    "    timer['net'] = time.time() - start\n",
    "\n",
    "    boxes, timer = detect(score_map=f_score, geo_map=f_geometry, timer=timer)\n",
    "    ratio_w = 512/frame_width\n",
    "    ratio_h = 512/frame_height\n",
    "    if boxes is not None:\n",
    "        scores = boxes[:,8].reshape(-1)\n",
    "        boxes = boxes[:, :8].reshape((-1, 4, 2))\n",
    "        boxes[:, :, 0] /= ratio_w\n",
    "        boxes[:, :, 1] /= ratio_h\n",
    "\n",
    "    duration = time.time() - start\n",
    "    timer['overall'] = duration\n",
    "    text_lines = []\n",
    "    if boxes is not None:\n",
    "        text_lines = []\n",
    "        for box, score in zip(boxes, scores):\n",
    "            box = sort_poly(box.astype(np.int32))\n",
    "            if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3]-box[0]) < 5:\n",
    "                continue\n",
    "            tl = collections.OrderedDict(zip(\n",
    "                ['x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3'],\n",
    "                map(float, box.flatten())))\n",
    "            tl['score'] = float(score)\n",
    "            text_lines.append(tl)\n",
    "    pred = {\n",
    "        'text_lines': text_lines\n",
    "    }\n",
    "    text_polys, text_tags = polys_array_list[index], tags_array_list[index]\n",
    "    text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (frame_height, frame_width))\n",
    "    # out.write(new_img)\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>Evaluation>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    targets = text_polys\n",
    "    precision, recall, f1 = eval_single_frame(targets, pred)\n",
    "    new_img = draw_illu(img.copy(), pred)\n",
    "    new_img1 = draw_illu_gt(new_img.copy(), targets, precision, recall, f1)\n",
    "    return precision, recall, f1, new_img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Video_39_2_3', 'Video_48_6_4', 'Video_5_3_2', 'Video_17_3_1', 'Video_35_2_3', 'Video_6_3_2', 'Video_11_4_1', 'Video_20_5_1', 'Video_49_6_4', 'Video_23_5_2', 'Video_44_6_4', 'Video_32_2_3', 'Video_53_7_4', 'Video_24_5_2', 'Video_1_1_2']\n"
     ]
    }
   ],
   "source": [
    "video_set = []\n",
    "test_data_path = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/test/'\n",
    "for root, dirs, files in os.walk(test_data_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp4'):\n",
    "            video_set.append(os.path.splitext(file)[0])\n",
    "print(video_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now it knows it's in a remote cluster\n"
     ]
    }
   ],
   "source": [
    "############################# 1. Glabol Variables #########################################\n",
    "################### 1.1 Training Setup\n",
    "ICDAR2013 = '/media/dragonx/DataLight/ICDAR2013/'\n",
    "ARC = '/media/dragonx/DataStorage/ARC/'\n",
    "############ Macros ############\n",
    "BASIC = \"basic\"\n",
    "CUDNN = \"cudnn\"\n",
    "BLOCK = \"block\"\n",
    "CONV  = \"conv2d\"\n",
    "CUDNN_INPUT_LINEAR_MODE = \"linear_input\"\n",
    "CUDNN_RNN_BIDIRECTION   = \"bidirection\"\n",
    "CUDNN_RNN_UNIDIRECTION = \"unidirection\"\n",
    "if platform.uname()[1] != 'dragonx-H97N-WIFI':\n",
    "    print(\"Now it knows it's in a remote cluster\")\n",
    "    ARC = '/work/cascades/lxiaol9/ARC/'\n",
    "    ICDAR2013 = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/'\n",
    "\n",
    "tf.app.flags.DEFINE_string('mode', 'test', 'whether debugging or real running')\n",
    "tf.app.flags.DEFINE_string(\"model\", \"test\", \"A type of model. Possible options are: small, medium, large.\")\n",
    "tf.app.flags.DEFINE_integer('input_size', 512, '')\n",
    "tf.app.flags.DEFINE_integer('batch_size_per_gpu', 8, '')\n",
    "tf.app.flags.DEFINE_integer('seq_len', 5, '')\n",
    "tf.app.flags.DEFINE_integer('num_steps', 5, '')\n",
    "tf.app.flags.DEFINE_string('gpu_list', '0,1', '')\n",
    "tf.app.flags.DEFINE_float('moving_average_decay', 0.9997, '')\n",
    "tf.app.flags.DEFINE_integer('num_gpus', 2, '')\n",
    "\n",
    "tf.app.flags.DEFINE_string('geometry', 'RBOX', 'which geometry to generate, RBOX or QUAD')\n",
    "tf.app.flags.DEFINE_string('checkpoint_path', '/work/cascades/lxiaol9/ARC/EAST/checkpoints/FLOW_east/20181109-210436/model.ckpt-31902', '')\n",
    "# Model 1: EAST\n",
    "tf.app.flags.DEFINE_string('pretrained_model_path', ARC + \"EAST/checkpoints/east/20180921-173054/model.ckpt-56092\", '')\n",
    "# Model 2: PWC-net\n",
    "tf.app.flags.DEFINE_string('flownet_type', \"large\", '')\n",
    "tf.app.flags.DEFINE_string(\"rnn_mode\", CONV, \"one of CUDNN: BASIC, BLOCK\")\n",
    "# Model 3: AGG\n",
    "tf.app.flags.DEFINE_string(\"prev_checkpoint_path\", \"/work/cascades/lxiaol9/ARC/EAST/checkpoints/GRU_agg/20181207-112241/model.ckpt-10343\", 'path' )\n",
    "#tf.app.flags.DEFINE_string(\"prev_checkpoint_path\", \"/work/cascades/lxiaol9/ARC/EAST/checkpoints/GRU_agg/20181207-123734/model.ckpt-6051\", 'path' )\n",
    "\n",
    "tf.app.flags.DEFINE_boolean(\"vis\", True, '')\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/work/cascades/lxiaol9/ARC/EAST/data/ICDAR2013/test_results_gruagg/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet_v1_50/block1 (?, ?, ?, 256)\n",
      "resnet_v1_50/block2 (?, ?, ?, 512)\n",
      "resnet_v1_50/block3 (?, ?, ?, 1024)\n",
      "resnet_v1_50/block4 (?, ?, ?, 2048)\n",
      "Shape of f_0 (?, ?, ?, 2048)\n",
      "Shape of f_1 (?, ?, ?, 512)\n",
      "Shape of f_2 (?, ?, ?, 256)\n",
      "Shape of f_3 (?, ?, ?, 64)\n",
      "Shape of h_0 (?, ?, ?, 2048), g_0 (?, ?, ?, 2048)\n",
      "Shape of h_1 (?, ?, ?, 128), g_1 (?, ?, ?, 128)\n",
      "Shape of h_2 (?, ?, ?, 64), g_2 (?, ?, ?, 64)\n",
      "Shape of h_3 (?, ?, ?, 32), g_3 (?, ?, ?, 32)\n",
      "INFO:tensorflow:Restoring parameters from /work/cascades/lxiaol9/ARC/EAST/checkpoints/east/20180921-173054/model.ckpt-56092\n",
      "continue training from previous checkpoint\n",
      "INFO:tensorflow:Restoring parameters from /work/cascades/lxiaol9/ARC/EAST/checkpoints/GRU_agg/20181207-112241/model.ckpt-10343\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]\n\nCaused by op 'save/Assign_28', defined at:\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-df70ab29ac33>\", line 257, in <module>\n    tf.app.run()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-5-df70ab29ac33>\", line 80, in main\n    saver1 = tf.train.Saver(tf.global_variables())\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1725\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1726\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]\n\nCaused by op 'save/Assign_28', defined at:\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-df70ab29ac33>\", line 257, in <module>\n    tf.app.run()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-5-df70ab29ac33>\", line 80, in main\n    saver1 = tf.train.Saver(tf.global_variables())\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-df70ab29ac33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-df70ab29ac33>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'continue training from previous checkpoint'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_checkpoint_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0msaver1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;31m# 2. for PWCnet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelPWCNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1757\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1759\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m   def _restore_from_object_based_checkpoint(self, sess, save_path,\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]\n\nCaused by op 'save/Assign_28', defined at:\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-df70ab29ac33>\", line 257, in <module>\n    tf.app.run()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\n    _sys.exit(main(argv))\n  File \"<ipython-input-5-df70ab29ac33>\", line 80, in main\n    saver1 = tf.train.Saver(tf.global_variables())\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/lxiaol9/anaconda3/envs/dlubu36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [1,1,64,4] rhs shape= [1,1,32,4]\n\t [[Node: save/Assign_28 = Assign[T=DT_FLOAT, _class=[\"loc:@pred_module/Conv_1/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](pred_module/Conv_1/weights, save/RestoreV2/_57)]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "FLAGS.vis = True\n",
    "#>>>>>>>>>>>>>>>>>>>>>>>>> specs for AGG >>>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
    "FLAGS.batch_size_per_gpu = 1\n",
    "FLAGS.seq_len = 5\n",
    "FLAGS.gpu_list ='1'\n",
    "FLAGS.num_gpus  = 1\n",
    "def main(argv=None):\n",
    "    config = get_config(FLAGS)\n",
    "    config.batch_size = FLAGS.batch_size_per_gpu * FLAGS.num_gpus\n",
    "    config.num_layers = 3\n",
    "    config.num_steps  = 5\n",
    "    ######################## Set up model configurations ######################\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> EAST model options >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    checkpoint_path = '/work/cascades/lxiaol9/ARC/EAST/checkpoints/east/'\n",
    "    idname1 = '20180921-173054'\n",
    "    idname2 = 'model.ckpt-56092'\n",
    "    model_path = checkpoint_path + idname1 + '/' + idname2\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>> PWCnet model options >>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    nn_opts = deepcopy(_DEFAULT_PWCNET_VAL_OPTIONS)\n",
    "    if FLAGS.flownet_type is 'small':\n",
    "        pwc_cfg = cfg_sm()\n",
    "        pwc_cfg.num_steps = FLAGS.seq_len\n",
    "        nn_opts['use_dense_cx'] = False\n",
    "        nn_opts['use_res_cx'] = False\n",
    "        nn_opts['pyr_lvls'] = 6\n",
    "        nn_opts['flow_pred_lvl'] = 2\n",
    "    else:\n",
    "        pwc_cfg = cfg_lg()\n",
    "        pwc_cfg.num_steps = FLAGS.seq_len\n",
    "        nn_opts['use_dense_cx'] = True\n",
    "        nn_opts['use_res_cx'] = True\n",
    "        nn_opts['pyr_lvls'] = 6\n",
    "        nn_opts['flow_pred_lvl'] = 2\n",
    "    nn_opts['verbose'] = True\n",
    "    nn_opts['ckpt_path'] = pwc_cfg.ckpt_path\n",
    "    nn_opts['batch_size'] = FLAGS.num_steps - 1      # This is Batch_size per GPU\n",
    "    nn_opts['use_tf_data'] = False  # Don't use tf.data reader for this simple task\n",
    "    nn_opts['gpu_devices'] = ['/device:GPU:1']    #\n",
    "    nn_opts['controller'] = '/device:CPU:0'     # Evaluate on CPU or GPU?\n",
    "    nn_opts['adapt_info'] = (1, 436, 1024, 2)\n",
    "    nn_opts['x_shape'] = [2, 512, 512, 3] # image pairs input shape [2, H, W, 3]\n",
    "    nn_opts['y_shape'] = [512, 512, 2] # u,v flows output shape [H, W, 2]\n",
    "    ################################ Model Initialization ############################\n",
    "    # 3. for EAST model \n",
    "    tf.reset_default_graph()\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "        input_images = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='input_images')\n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "        score_raw, geometry_raw, feature_raw = model.model(input_images, is_training=False)\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(0.997, global_step)\n",
    "        saver = tf.train.Saver(variable_averages.variables_to_restore())\n",
    "        sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "        logger.info('Restore from {}'.format(model_path))\n",
    "        saver.restore(sess, model_path)\n",
    "        # Build the graph\n",
    "    tf.reset_default_graph()\n",
    "    g1 = tf.Graph()\n",
    "    with g1.as_default():\n",
    "        batch_size = FLAGS.batch_size_per_gpu * FLAGS.num_gpus\n",
    "        len_seq = FLAGS.num_steps\n",
    "        input_feat_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 32], name='input_feature_maps')\n",
    "        input_flow_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq-1, 128, 128, 2], name='input_flow_maps')\n",
    "        input_score_maps = tf.placeholder(tf.float32, shape=[batch_size , len_seq, 128, 128, 1], name='input_score_maps')\n",
    "#         if FLAGS.geometry == 'RBOX':\n",
    "#             input_geo_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 5], name='input_geo_maps')\n",
    "#         else:\n",
    "#             input_geo_maps = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 8], name='input_geo_maps')\n",
    "#         input_training_masks = tf.placeholder(tf.float32, shape=[batch_size, len_seq, 128, 128, 1], name='input_training_masks'\n",
    "        reuse_variables = None\n",
    "        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "        score_map_set, geo_map_set = model_gru_concat.build_model(input_feat_maps, input_flow_maps, config=config, reuse_variables=reuse_variables)\n",
    "        config1 = tf.ConfigProto()\n",
    "        config1.gpu_options.allow_growth = True\n",
    "        config1.allow_soft_placement = True\n",
    "        sess1 = tf.Session(config=config1)\n",
    "        # \n",
    "        saver1 = tf.train.Saver(tf.global_variables())\n",
    "        print('continue training from previous checkpoint')\n",
    "        ckpt = FLAGS.prev_checkpoint_path\n",
    "        saver1.restore(sess1, ckpt)\n",
    "    # 2. for PWCnet model \n",
    "    nn = ModelPWCNet(mode='test', options=nn_opts)\n",
    "    start = time.time()\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>Start evaluation>>>>>>>>>>>>>>>>>>>>>>>>>#\n",
    "    P_test = []\n",
    "    R_test = []\n",
    "    f1_test= []\n",
    "    index = range(3, 4)\n",
    "    file_txt = save_path + 'eval_gruagg_20181207-112241.txt'\n",
    "    file1 = open(file_txt,\"w+\")\n",
    "    file1.close()\n",
    "    for k in index:\n",
    "        P_video = []\n",
    "        R_video = []\n",
    "        f1_video = []\n",
    "        new_detections = []\n",
    "        video_save = save_path + video_set[k] + idname1 + '_' + idname2 + '.avi'\n",
    "        t_start = time.time()\n",
    "        # sort up all the paths\n",
    "        xml_solo_path = test_data_path + video_set[k]\n",
    "        raw_video_path = test_data_path + video_set[k]+'.mp4'\n",
    "        cap = cv2.VideoCapture(raw_video_path)\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height= int(cap.get(4))\n",
    "        cnt_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print('Now testing '+video_set[k] + ' with %d frames'%(cnt_frame))\n",
    "        out = cv2.VideoWriter(video_save, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "        \n",
    "        # 1. load both polys and tags; 2. generate geo maps(the format of polys and tags need to match)\n",
    "        polys_array_list, tags_array_list, id_list_list, frame_num = load_annotations_solo(xml_solo_path, \\\n",
    "                    1, cnt_frame, frame_width, frame_height)\n",
    "        #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>loop over frames in the time steps, one by one>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        data_original = np.zeros((FLAGS.batch_size_per_gpu, FLAGS.num_steps, frame_height, frame_width, 3))\n",
    "        data_seq = np.zeros((FLAGS.batch_size_per_gpu, FLAGS.num_steps, 512, 512, 3))\n",
    "        for m in range(FLAGS.num_steps):\n",
    "            cap.set(1, m)\n",
    "            ret, frame = cap.read()\n",
    "            im_resized = cv2.resize(frame, (int(512), int(512)))\n",
    "            data_original[0, m, :, :,:] = frame\n",
    "            data_seq[0, m, :, : , :] = im_resized\n",
    "        half_size = int((FLAGS.num_steps- 1)/2)\n",
    "#         for i in range(half_size, cnt_frame-half_size):\n",
    "        for i in range(20, 60):\n",
    "            start = time.time()\n",
    "            cap.set(1, half_size + i)\n",
    "            ret, frame = cap.read()\n",
    "            im_resized = cv2.resize(frame, (int(512), int(512)))\n",
    "            if i>half_size:\n",
    "                data_original[0,0:(FLAGS.seq_len-1), :, :, :] = data_original[0, 1:FLAGS.seq_len, :, :, :]\n",
    "                data_seq[0,0:(FLAGS.seq_len-1), :, :, :] = data_seq[0, 1:FLAGS.seq_len, :, :, :]\n",
    "                data_original[0,FLAGS.seq_len-1, :, :, :] = frame\n",
    "                data_seq[0, FLAGS.seq_len-1, :, :, :] = im_resized\n",
    "            # feed data for east net\n",
    "            east_feed = np.reshape(data_seq, [-1, 512, 512, 3])\n",
    "            ratio_h, ratio_w = 512/frame_height, 512/frame_width\n",
    "            # feed data for flow net \n",
    "            target_frame = np.reshape(np.array(data_seq)[:, 0:4, :, : , :], [-1, 512, 512, 3])\n",
    "            source_frame = np.reshape(np.array(data_seq)[:, 1:5, :, : , :], [-1, 512, 512, 3])\n",
    "            flow_feed = np.concatenate((source_frame[:, np.newaxis, :, :, :], target_frame[:, np.newaxis, :, :, :]), axis = 1)\n",
    "            # >>>>>>>>>>>>>>>>>>>>>>>>>>> feature extraction with EAST >>>>>>>>>>>>>>>>>>>>>>>> #\n",
    "            mini_batch = 5\n",
    "            rounds = int(east_feed.shape[0]/mini_batch)\n",
    "            feature_stack = []\n",
    "            flow_maps_stack = []\n",
    "            score_stack = []\n",
    "            geo_stack = []\n",
    "            with g.as_default():\n",
    "                for r in range(rounds):\n",
    "                    score_map_east, geo_map_east, feature = sess.run([score_raw, geometry_raw, feature_raw],feed_dict={input_images: east_feed[r*mini_batch:(r+1)*mini_batch, :, :, ::-1]})\n",
    "                    feature_stack.append(feature)\n",
    "                    score_stack.append(score_map_east)\n",
    "                    geo_stack.append(geo_map_east)\n",
    "            feature_maps = np.concatenate(feature_stack, axis=0)\n",
    "            feature_maps_reshape = np.reshape(feature_maps, [-1, config.num_steps, 128, 128, 32])\n",
    "#             feature_maps[2, :, :, :] = prev_feature \n",
    "            # score, geo for original east \n",
    "            score_maps = np.concatenate(score_stack, axis=0)\n",
    "            geo_maps = np.concatenate(geo_stack, axis=0)\n",
    "            # >>>>>>>>>>>>>>>>>>>>>>>>>>> flow estimation with PWCnet >>>>>>>>>>>>>>>>>>>>>>>>> #\n",
    "            x_adapt, x_adapt_info = nn.adapt_x(flow_feed)\n",
    "            if x_adapt_info is not None:\n",
    "                y_adapt_info = (x_adapt_info[0], x_adapt_info[2], x_adapt_info[3], 2)\n",
    "            else:\n",
    "                y_adapt_info = None\n",
    "            # Run the adapted samples through the network\n",
    "            mini_batch = nn_opts['batch_size']*nn.num_gpus\n",
    "            rounds = int(flow_feed.shape[0]/mini_batch)\n",
    "            for r in range(rounds):\n",
    "                feed_dict = {nn.x_tnsr: x_adapt[r*mini_batch:(r+1)*mini_batch, :, :, :, :]}\n",
    "                y_hat = nn.sess.run(nn.y_hat_test_tnsr, feed_dict=feed_dict)\n",
    "                y_hats, _ = nn.postproc_y_hat_test(y_hat, y_adapt_info)# suppose to be [batch, height, width, 2]\n",
    "                flow_maps_stack.append(y_hats[:, 1::4, 1::4, :]/4)\n",
    "            flow_maps = np.concatenate(flow_maps_stack, axis=0)\n",
    "            flow_maps = np.reshape(flow_maps, [-1, FLAGS.num_steps-1, 128, 128, 2])\n",
    "            # display_img_pairs_w_flows(img_pairs, pred_labels)\n",
    "            #>>>>>>>>>>>>>>>>>>>>>>>> Generate results with gru-agg model >>>>>>>>>>>>>>>>>>>>\n",
    "            with g1.as_default():\n",
    "                geo_results, sco_results = sess1.run([geo_map_set, score_map_set], feed_dict={input_feat_maps:feature_maps_reshape,\n",
    "                                                                  input_flow_maps:flow_maps})\n",
    "            #>>>>>>>>>>>>>>>>>>>>>>>>Okay!!!We could evalute the results now>>>>>>>>>>>>>>>>>>>\n",
    "            #Results refinement via NMS\n",
    "            for t in range(FLAGS.num_steps-1, FLAGS.num_steps):\n",
    "                img = data_original[0, t, :, :,:]\n",
    "                f_score = sco_results[t][np.newaxis, :, :, :]\n",
    "                f_geometry = geo_results[t][np.newaxis, :, :, :]\n",
    "#                 import pdb;pdb.set_trace()\n",
    "                precision, recall, f1, new_img1 = box_generation(i+half_size, img, frame_height, frame_width, f_score, f_geometry, polys_array_list, tags_array_list, start)\n",
    "                print(\"New Model:results on frame {} is P:{}, R{}, F:{}\".format(i, precision, recall, f1))\n",
    "                new_detections.append(new_img1)\n",
    "                P_video.append(precision)\n",
    "                R_video.append(recall)\n",
    "                f1_video.append(f1)\n",
    "                precision_e, recall_e, f1_e, new_img1_e = box_generation(i+half_size, img, frame_height, frame_width, score_maps[t][np.newaxis, :, :, :], geo_maps[t][np.newaxis, :, :, :], polys_array_list, tags_array_list, start)\n",
    "                print(\"EAST Model:results on frame {} is P:{}, R{}, F:{}\".format(i, precision_e, recall_e, f1_e))\n",
    "                vis_save_path = save_path + video_set[k] + '/'\n",
    "                if not os.path.exists(vis_save_path):\n",
    "                    os.makedirs(vis_save_path) \n",
    "                import pdb;pdb.set_trace()\n",
    "                if FLAGS.vis:\n",
    "    #                 fig = plt.figure(figsize=(15, 6), dpi=300)\n",
    "    #                 for t in range(FLAGS.seq_len):\n",
    "    #                     ax1 = fig.add_subplot(2, FLAGS.seq_len, t+1, aspect='equal')\n",
    "    #                     ax1.set_title('frame{}'.format(i-mf_ind+t))\n",
    "    #                     plt.axis('off')\n",
    "    #                     ax1.imshow(data_original[0, t, :, :,:].astype(np.uint8))\n",
    "    #                     ax2 = fig.add_subplot(2, FLAGS.seq_len, FLAGS.seq_len+t+1, aspect='equal')\n",
    "    #                     ax2.set_title('score-map{}'.format(i-mf_ind+t))\n",
    "    #                     plt.axis('off')\n",
    "    #                     ax2.imshow((np.squeeze(score_maps[t]*255)).astype(np.uint8)) \n",
    "    #                 fig.savefig(vis_save_path+\"east_frame\" + str(i) + \".png\", dpi=500)\n",
    "                    fig1 = plt.figure(figsize=(8, 8), dpi=300)\n",
    "                    fig1.add_subplot(2, 2, 1, aspect='equal')\n",
    "                    plt.imshow(new_img1_e.astype(np.uint8))\n",
    "                    plt.title('frame {} with EAST'.format(i))\n",
    "                    plt.axis('off')\n",
    "                    fig1.add_subplot(2, 2, 2, aspect='equal')\n",
    "                    plt.imshow(new_img1.astype(np.uint8))\n",
    "                    plt.title('frame {} with New Model'.format(i))\n",
    "                    plt.axis('off')\n",
    "                    fig1.add_subplot(2, 2, 3, aspect='equal')\n",
    "                    plt.imshow((np.squeeze(score_maps[half_size]*255)).astype(np.uint8))\n",
    "                    plt.title('Score map with EAST')\n",
    "                    plt.axis('off')\n",
    "                    fig1.add_subplot(2, 2, 4, aspect='equal')\n",
    "                    plt.imshow((np.squeeze(f_score*255)).astype(np.uint8))\n",
    "                    plt.title('Score Map with New Model')\n",
    "                    plt.axis('off')\n",
    "                    plt.show()\n",
    "                    fig1.savefig(vis_save_path+\"fuse_frame\" + str(i) + \".png\", dpi=500)\n",
    "            # evaluation on ret and gt\n",
    "            P_test.append(np.array(P_video, dtype=np.float32))\n",
    "            R_test.append(np.array(R_video, dtype=np.float32))\n",
    "            f1_test.append(np.array(f1_video, dtype=np.float32))\n",
    "        print(np.mean(P_video))\n",
    "        print(np.mean(R_video))\n",
    "        print(np.mean(f1_video))\n",
    "#         import pdb;pdb.set_trace()\n",
    "        with open(file_txt, \"a+\") as f:\n",
    "            f.write(video_set[k]+' PRECISION: '+' '.join([\"{:0.6f}\".format(x) for x in P_video])+'\\n')\n",
    "            f.write(video_set[k]+' RECALL: '+' '.join([\"{:0.6f}\".format(x) for x in R_video])+'\\n')\n",
    "            f.write(video_set[k]+' F1 SCORE: '+' '.join([\"{:0.6f}\".format(x) for x in f1_video])+'\\n')\n",
    "        cap.release()\n",
    "    print('here is the precision')\n",
    "    for item in P_test:\n",
    "        print(np.mean(item))\n",
    "    print('here is the recall')\n",
    "    for item in R_test:\n",
    "        print(np.mean(item))\n",
    "    print('here is the f-score')\n",
    "    for item in f1_test:\n",
    "        print(np.mean(item))\n",
    "    print(video_set)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
